{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Data Processing Usage\n",
    "\n",
    "Methods for text data processing:  \n",
    "[Processor Documentation](../../docs/text_process.md)\n",
    "\n",
    "Below is a simple example of a YAML configuration file (format of `configs/process/text_process_example.yaml`):\n",
    "\n",
    "```yaml\n",
    "model_cache_path: '../ckpt' # Path for model caching\n",
    "dependencies: [text]\n",
    "save_path: \"./processed.jsonl\"\n",
    "\n",
    "data:\n",
    "  text:\n",
    "    use_hf: False # Whether to use huggingface_dataset; if used, the following local data path is ignored\n",
    "    dataset_name: 'yahma/alpaca-cleaned'\n",
    "    dataset_split: 'train'  \n",
    "    name: 'default' \n",
    "    revision: null\n",
    "    data_path: 'demos/text_process/fineweb_5_samples.json'  # Local data path, supports json, jsonl, parquet formats\n",
    "    formatter: \"TextFormatter\" # Data loader type\n",
    "\n",
    "    keys: 'text' # Key name to process; for SFT data, it can be specified as ['instruction','input','output']\n",
    "```\n",
    "The `data` section specifies the path to the data file/folder and related configurations.\n",
    "```yaml\n",
    "processors:\n",
    "  RemoveExtraSpacesRefiner: {} # Removes extra spaces\n",
    "  CCNetDeduplicator: \n",
    "    bit_length: 64 \n",
    "  NgramFilter:\n",
    "    min_score: 0.99\n",
    "    max_score: 1.0\n",
    "    scorer_args:\n",
    "      ngrams: 5 # Specifies the n-gram value\n",
    "```\n",
    "The configuration under `processors` specifies the parameters for the processors being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/petrelfs/zhaozhengyang/miniconda3/envs/datagym/lib/python3.9/site-packages/torch/cuda/__init__.py:654: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "target_dir = os.path.abspath('../..') \n",
    "current_dir = os.getcwd()\n",
    "\n",
    "if current_dir != target_dir:\n",
    "    os.chdir(target_dir)  \n",
    "\n",
    "dataflow_path = os.path.abspath(os.path.join(os.getcwd(), '..', '..')) \n",
    "sys.path.insert(0, dataflow_path)\n",
    "sys.argv = ['notebook', '--config', 'configs/process/text_process_example.yaml']\n",
    "\n",
    "from dataflow.utils.utils import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RemoveExtraSpacesRefiner {'num_workers': 1, 'model_cache_dir': '../ckpt'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Implementing RemoveExtraSpacesRefiner: 100%|██████████| 5/5 [00:00<00:00, 1969.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Implemented RemoveExtraSpacesRefiner. 4 data refined.\n",
      "CCNetDeduplicator {'bit_length': 64, 'num_workers': 1, 'model_cache_dir': '../ckpt'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module dataflow.process.text.refiners has no attribute CCNetDeduplicator\n",
      "Module dataflow.process.text.filters has no attribute CCNetDeduplicator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Implementing CCNetDeduplicator: 100%|██████████| 5/5 [00:00<00:00, 14112.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Implemented CCNetDeduplicator. Data Number: 5 -> 4\n",
      "NgramFilter {'min_score': 0.99, 'max_score': 1.0, 'scorer_args': {'ngrams': 5}, 'num_workers': 1, 'model_cache_dir': '../ckpt'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module dataflow.process.text.refiners has no attribute NgramFilter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating NgramScore: 100%|██████████| 4/4 [00:00<00:00, 337.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Implemented NgramFilter. Data Number: 4 -> 3\n",
      "Data saved to ./processed.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "process()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datagym",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
